
using LearnConvection
using Plots

D=16
N=8

problem  = Sequential("dT")

train = ["general_strat_4_profiles.jld2", "general_strat_32_profiles.jld2"]
ğ’Ÿ_train = LearnConvection.Data.data(train, problem; D=D, N=N)
ğ’Ÿ_validate  = LearnConvection.Data.data("general_strat_16_profiles.jld2", problem; D=D, N=N)
ğ’Ÿ_test = LearnConvection.Data.data("general_strat_32_profiles.jld2", problem; D=D, N=N)

ğ’¢ = LearnConvection.GaussianProcess.model(ğ’Ÿ_train; kernel=get_kernel(4,0.0,0.0,euclidean_distance))
predict(ğ’¢, ğ’Ÿ_train; postprocessed=true)
LearnConvection.GaussianProcess.get_me_true_check(ğ’¢, ğ’Ÿ_validate)

k=3
distance=euclidean_distance
get_min_gamma(k, distance, ğ’Ÿ_train, ğ’Ÿ_validate, ğ’Ÿ_test; log_Î³s=-0.4:0.1:0.4)


##






using LearnConvection
using Plots

# Construct a ProfileData object, ğ’Ÿ, consisting of the data to train on,
# and a GP object, ğ’¢, with which to perform the regression.

# data
filename = "general_strat_32_profiles.jld2"
problem  = Residual("KPP", KPP.Parameters()) # v: "T" for temperature profile; "wT" for temperature flux profile
problem  = Residual("TKE", TKEMassFlux.TKEParameters())
D        = 32       # collapse profile data down to 16 gridpoints
N        = 4        # collect every 4 timesteps' data for training

# Now let's define our kernel. We don't know what the best long(length-scale) parameter value is yet so let's guess 0.0 (Î³=1) and see what happens.
# Let's use an exponential kernel.

# kernel
k        = 3        # kernel function ID
logÎ³     = -0.6      # log(length-scale parameter)
logÏƒ     = 0.0      # log(signal variance parameter)
distance = derivative_distance  # distance metric to use in the kernel
kernel   = get_kernel(k, logÎ³, logÏƒ, distance)

# data
ğ’Ÿ_train = LearnConvection.Data.data(["general_strat_16_profiles.jld2","general_strat_32_profiles.jld2"], problem; D=D, N=N)
ğ’Ÿ_test = LearnConvection.Data.data("general_strat_32_profiles.jld2", problem; D=D, N=N)

# model
ğ’¢ = LearnConvection.GaussianProcess.model(ğ’Ÿ_train; kernel = kernel)

# Animate the mean GP prediction.
# anim = animate_profile(ğ’¢, ğ’Ÿ)
# gif(anim, "animated_profile.gif")

anim = animate_profile_and_model_output(ğ’¢, ğ’Ÿ_test)
gif(anim, "animated_profile_and_model_output_KPP32_train_gs16_gs32_test_gs32.gif")

##

# Not great. Let's try to optimize our Î³ value.
# We can use get_min_gamma function to search the range -2:0.1:2 for the log(Î³) value that minimizes the mean error on the true check
min_log_param, min_error = get_min_gamma(k, ğ’Ÿ, distance, -2:0.01:2)

# Let's create a kernel with the better log(Î³) value, put the new kernel into a new model, and see how it does.
new_kernel = get_kernel(k, min_log_param, logÏƒ, distance)
ğ’¢ = LearnConvection.GaussianProcess.model(ğ’Ÿ; kernel = new_kernel)
anim = animate_profile(ğ’¢, ğ’Ÿ)
gif(anim, "animated_profile_optimized.gif")

# There's a lot of flexibility in how we design our kernel function.
# We can modify the hyperparameter values, the distance metric, and the type of kernel function.

p1 = plot([1 2 3], [4 5 6], title="hello", ylabel="yes")
p2 = plot([1 2 3], [4 5 6])
p3 = plot([1 2 3], [4 5 6])
p4 = plot([1 2 3], [4 5 6])
p5 = plot([1 2 3], [4 5 6])
p6 = plot([1 2 3], [4 5 6])

layout = @layout [a b c; d e f]
titles = ["Sq Exp / lÂ²-norm" "MatÃ©rn 1/2 / lÂ²-norm" "MatÃ©rn 3/2 / lÂ²-norm" "Sq Exp / HÂ¹-norm" "Sq Exp / HÂ¹-norm" "Sq Exp / HÂ¹-norm"]

plot(p1, p2, p3, p4, p5, p6; layout = layout, title=titles)






# data
ğ’Ÿ = OceanConvect.ModelData.data("general_strat_16_profiles.jld2", Sequential("dT"); D=16, N=4)
logÎ³s = -3.0:0.1:3.0
p1  = plot_landscapes_compare_error_metrics(1, ğ’Ÿ, euclidean_distance, log_Î³s)
p2  = plot_landscapes_compare_error_metrics(2, ğ’Ÿ, euclidean_distance, log_Î³s)
p3  = plot_landscapes_compare_error_metrics(3, ğ’Ÿ, euclidean_distance, log_Î³s)
p4  = plot_landscapes_compare_error_metrics(4, ğ’Ÿ, euclidean_distance, log_Î³s)
p5  = plot_landscapes_compare_error_metrics(5, ğ’Ÿ, euclidean_distance, log_Î³s)
p6  = plot_landscapes_compare_error_metrics(1, ğ’Ÿ, derivative_distance, log_Î³s)
p7  = plot_landscapes_compare_error_metrics(2, ğ’Ÿ, derivative_distance, log_Î³s)
p8  = plot_landscapes_compare_error_metrics(3, ğ’Ÿ, derivative_distance, log_Î³s)
p9  = plot_landscapes_compare_error_metrics(4, ğ’Ÿ, derivative_distance, log_Î³s)
p10 = plot_landscapes_compare_error_metrics(5, ğ’Ÿ, derivative_distance, log_Î³s)
p11 = plot_landscapes_compare_error_metrics(1, ğ’Ÿ, antiderivative_distance, log_Î³s)
p12 = plot_landscapes_compare_error_metrics(2, ğ’Ÿ, antiderivative_distance, log_Î³s)
p13 = plot_landscapes_compare_error_metrics(3, ğ’Ÿ, antiderivative_distance, log_Î³s)
p14 = plot_landscapes_compare_error_metrics(4, ğ’Ÿ, antiderivative_distance, log_Î³s)
p15 = plot_landscapes_compare_error_metrics(5, ğ’Ÿ, antiderivative_distance, log_Î³s)








##

# problems
params   = KPP.Parameters( CSL = 1.0, CNL = 1.0, Cb_T = 1.0, CKE = 1.0)
params   = KPP.Parameters( )

problem  = Residual("KPP", params) # v: "T" for temperature profile; "wT" for temperature flux profile

problem  = Sequential("dT") # v: "T" for temperature profile; "wT" for temperature flux profile

# data
filename = "general_strat_32_profiles.jld2"
D        = 16
N        = 4

# kernel
k        = 1
logÎ³     = -3.0
logÏƒ     = 0.0
distance = euclidean_distance
kernel   = get_kernel(k, logÎ³, logÏƒ, distance)

# data
ğ’Ÿ = LearnConvection.Data.data(filename, problem; D=D, N=N)

# model
ğ’¢ = LearnConvection.GaussianProcess.model(ğ’Ÿ; kernel = kernel)

# Animate the mean GP prediction.
anim = animate_profile(ğ’¢, ğ’Ÿ)
gif(anim, "animated_profile.gif")
